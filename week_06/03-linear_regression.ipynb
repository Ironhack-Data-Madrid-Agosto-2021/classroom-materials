{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![memesitodeldía](../images/linear.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Simple-linear-regression\" data-toc-modified-id=\"Simple-linear-regression-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Simple linear regression</a></span></li><li><span><a href=\"#Generamos-datos-para-explicar-de-forma-&quot;inversa&quot;-a-lo-visto-ayer-en-clase\" data-toc-modified-id=\"Generamos-datos-para-explicar-de-forma-&quot;inversa&quot;-a-lo-visto-ayer-en-clase-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Generamos datos para explicar de forma \"inversa\" a lo visto ayer en clase</a></span></li><li><span><a href=\"#Configuraciones-para-poner-mono-el-plot-de-seaborn\" data-toc-modified-id=\"Configuraciones-para-poner-mono-el-plot-de-seaborn-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Configuraciones para poner mono el plot de seaborn</a></span></li><li><span><a href=\"#¿Cómo-de-bueno-es-nuestro-modelo?\" data-toc-modified-id=\"¿Cómo-de-bueno-es-nuestro-modelo?-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>¿Cómo de bueno es nuestro modelo?</a></span></li><li><span><a href=\"#Calculamos-el-R2-del-modelo\" data-toc-modified-id=\"Calculamos-el-R2-del-modelo-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Calculamos el R2 del modelo</a></span></li><li><span><a href=\"#Regresión-lineal-con-sklearn\" data-toc-modified-id=\"Regresión-lineal-con-sklearn-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Regresión lineal con sklearn</a></span></li><li><span><a href=\"#Regresión-lineal-con-statsmodels\" data-toc-modified-id=\"Regresión-lineal-con-statsmodels-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Regresión lineal con statsmodels</a></span></li><li><span><a href=\"#Conceptos-del-OLS\" data-toc-modified-id=\"Conceptos-del-OLS-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Conceptos del OLS</a></span></li><li><span><a href=\"#Regresión-lineal-múltiple\" data-toc-modified-id=\"Regresión-lineal-múltiple-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Regresión lineal múltiple</a></span></li><li><span><a href=\"#Variables-categóricas\" data-toc-modified-id=\"Variables-categóricas-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Variables categóricas</a></span></li><li><span><a href=\"#Extensiones-del-modelo-lineal\" data-toc-modified-id=\"Extensiones-del-modelo-lineal-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Extensiones del modelo lineal</a></span><ul class=\"toc-item\"><li><span><a href=\"#Desafiando-la-suposición-aditiva:-la-sinergia\" data-toc-modified-id=\"Desafiando-la-suposición-aditiva:-la-sinergia-11.1\"><span class=\"toc-item-num\">11.1&nbsp;&nbsp;</span>Desafiando la suposición aditiva: la sinergia</a></span></li></ul></li><li><span><a href=\"#Manos-a-la-obra\" data-toc-modified-id=\"Manos-a-la-obra-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Manos a la obra</a></span></li><li><span><a href=\"#Selección-de-modelo\" data-toc-modified-id=\"Selección-de-modelo-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Selección de modelo</a></span><ul class=\"toc-item\"><li><span><a href=\"#$R^2$-Ajustado\" data-toc-modified-id=\"$R^2$-Ajustado-13.1\"><span class=\"toc-item-num\">13.1&nbsp;&nbsp;</span>$R^2$ Ajustado</a></span></li></ul></li><li><span><a href=\"#Selección-por-pasos\" data-toc-modified-id=\"Selección-por-pasos-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>Selección por pasos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Best-subset-selection\" data-toc-modified-id=\"Best-subset-selection-14.1\"><span class=\"toc-item-num\">14.1&nbsp;&nbsp;</span>Best subset selection</a></span></li><li><span><a href=\"#Modelo-nulo\" data-toc-modified-id=\"Modelo-nulo-14.2\"><span class=\"toc-item-num\">14.2&nbsp;&nbsp;</span>Modelo nulo</a></span></li><li><span><a href=\"#Forward-stepwise-selection\" data-toc-modified-id=\"Forward-stepwise-selection-14.3\"><span class=\"toc-item-num\">14.3&nbsp;&nbsp;</span>Forward stepwise selection</a></span></li></ul></li><li><span><a href=\"#Problemas-potenciales-en-la-regresión-lineal\" data-toc-modified-id=\"Problemas-potenciales-en-la-regresión-lineal-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>Problemas potenciales en la regresión lineal</a></span></li><li><span><a href=\"#Resumen\" data-toc-modified-id=\"Resumen-16\"><span class=\"toc-item-num\">16&nbsp;&nbsp;</span>Resumen</a></span></li><li><span><a href=\"#Further-Materials\" data-toc-modified-id=\"Further-Materials-17\"><span class=\"toc-item-num\">17&nbsp;&nbsp;</span>Further Materials</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualización\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "%matplotlib inline\n",
    "%config Inlinebackend.figure_format = 'retina'\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Librerías de modelado\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple linear regression\n",
    "\n",
    "Regresión lineal simple un modelo estadístico que supone una relación lineal entre un predictor y una variable objetivo. Matemáticamente, se puede expresar como:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![formula](../images/formula.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si profundizamos un poco más, podemos encontrar esta otra expresión:\n",
    "\n",
    " $$ Y = \\beta_0 +  \\beta_1 X + \\epsilon$$\n",
    "\n",
    "Donde:\n",
    " * $X$ = variable predictora\n",
    " * $Y$ = variable objetivo\n",
    " * $\\beta_0$ = intercept\n",
    " * $\\beta_1$ = pendiente / slope\n",
    " * $\\epsilon$ = ruido (gaussiano)\n",
    "\n",
    "\n",
    "La ecuación anterior se conoce como *línea de regresión poblacional*.\n",
    "La línea de regresión lineal simple suele tener la forma que se muestra en la fórmula anterior, donde β0 y β1 son constantes desconocidas, que representan el intercepto y la pendiente de la línea de regresión, respectivamente.\n",
    "\n",
    "El intercepto es el valor de la variable dependiente (Y) cuando la variable independiente (X) tiene un valor de cero (0). La pendiente es una medida de la velocidad a la que cambia la variable dependiente (Y) cuando la variable independiente (X) cambia en uno (1). Las constantes desconocidas se denominan coeficientes o parámetros del modelo. Esta forma de la línea de regresión se conoce a veces como línea de regresión poblacional y, como modelo probabilístico, se ajusta al conjunto de datos de forma aproximada de ahí el uso del símbolo (≈) en la imagen. El modelo se denomina probabilístico porque no modela toda la variabilidad de la variable dependiente (Y) : El modelo se llama probabilístico porque no modela toda la variabilidad de la variable dependiente (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../datasets/hours_vs_mark.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hacíamos predicciones en base a una inferencia de beta_0 y beta_1 (m,n / pendiente, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Del ejemplo visto ayer en clase\n",
    "beta_0 = 10\n",
    "beta_1 = 0.084"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"predict\"] = beta_1 * data.hours + beta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculábamos el error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"error\"] = (data.mark - data.predict).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAE (MEAN ABSOLUT ERROR)\n",
    "data.error.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generamos datos para explicar de forma \"inversa\" a lo visto ayer en clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Del ejemplo visto ayer en clase \n",
    "beta_0 = 10\n",
    "beta_1 = 0.08\n",
    "num_notas = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentación de np.random normal --> https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html    \n",
    "Parámetros : \n",
    "- Media\n",
    "- Desviación estándar\n",
    "- Tamaño de la muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos las horas de estudio\n",
    "X = np.random.normal(600,150,num_notas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la hora de generar las notas metemos ese np.random.normal que va a ser un número aleatorio para cada nota que va a hacer que la nota varie. Es un error aleatorio. Lo ponemos porque nos estamos inventando los datos y si lo hacemos simplemente a través de la fórmula de una recta, evidentemente, tendremos unos datos que se ajusten a una regresión A LA PERFECCIÓN y eso no es real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos las notas\n",
    "y = beta_0 + (beta_1 * X) + np.random.normal(loc=0, scale=5, size=num_notas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos el dataframe\n",
    "data = pd.DataFrame({\"horas\": X, \"nota\":y}).round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuraciones para poner mono el plot de seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('poster')\n",
    "sns.set(rc={'figure.figsize': (16., 9.)})\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pintamos la línea de regresión de los datos que acabamos de generar\n",
    "sns.regplot(x=\"horas\", y=\"nota\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pintamos un ejemplo de los datos SIN ERROR ALEATORIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos las horas de estudio\n",
    "beta_0 = 10\n",
    "beta_1 = 0.08\n",
    "num_notas = 100\n",
    "X_irreal = np.random.normal(600,150,num_notas)\n",
    "# la y es simplemente la ecuación de la recta y es la nota que sacas\n",
    "y_irreal = beta_0 + (beta_1 * X_irreal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_irreal = pd.DataFrame({\"horas\": X_irreal, \"nota\":y_irreal}).round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"horas\", y=\"nota\", data=data_irreal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por supuesto, en la vida real no conocemos los verdaderos parámetros del modelo, ¡¡¡ni si el modelo es real!!! Hoy vamos a aprender una [valiosa lección](https://en.wikipedia.org/wiki/All_models_are_wrong):\n",
    "\n",
    "\n",
    "\n",
    "<center> <b>\"Todos los modelos son erróneos, pero algunos son útiles\"</b> </center>\n",
    "\n",
    "\n",
    "En la práctica lo que hacemos es, tras ver un gráfico de dispersión como el de arriba, intentar inferir los parámetros del modelo $\\beta_0$ y la pendiente, $\\beta_1$.  Una vez estimados, el ajuste estimado se convierte en $$ \\hat{Y} = \\hat{beta_0} + \\hat{beta_1} X$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a entrenar un modelo de regresión que saque los coeficientes con sklearn y lo hacemos con el primer modelo que hemos generado que llevaba RUIDO/ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(\n",
    "    \n",
    "    X = data[[\"horas\"]],\n",
    "    y = data.nota\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder para la vida sintaxis de un modelo de ML\n",
    "\n",
    "```python\n",
    "SINTAXIS = MODELO.FIT (X,y)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1 = lr.coef_[0]\n",
    "beta_0 = lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"beta_1\")\n",
    "print(beta_1)\n",
    "print(\"beta_0\")\n",
    "print(beta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(\n",
    "    \n",
    "    X = data_irreal[[\"horas\"]],\n",
    "    y = data_irreal.nota\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora lo hacemos con los datos QUE NO LLEVAN RUIDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1_irreal = lr.coef_[0]\n",
    "beta_0_irreal = lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"beta_1\")\n",
    "print(beta_1_irreal)\n",
    "print(\"beta_0\")\n",
    "print(beta_0_irreal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a pintar la línea de regresión con el residuo\n",
    "y_hat = beta_0 + beta_1 * X # Línea de regresión\n",
    "plt.scatter(X,y) # pintar los puntos\n",
    "plt.plot(X,  y_hat, lw=2) #pintamos la línea de regresión\n",
    "plt.vlines(X, y_hat, y, lw=0.4) #pintamos las líneas que van desde los puntos a la línea de regresión (Residuo)\n",
    "plt.xlabel(\"horas\")\n",
    "plt.ylabel(\"nota\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo de bueno es nuestro modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La diferencia numérica entre la *línea de regresión de mínimos cuadrados* y el valor real se llama *residuo* , y representa el error en la estimación: $e = y_i - \\hat{y}$.     \n",
    "La línea de regresión minimizó la *Suma de cuadrados residual* (RSS)     \n",
    "\n",
    "$$RSS = e_1^2 + e_2^2 + \\dots + e_n ^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si sólo utilizamos la media como valor predicho para cada predicción, el error que cometeríamos es (*suma total de cuadrados*)\n",
    "\n",
    "$$TTS=\\Sigma(y_i - \\bar{y}_i)^2$$\n",
    "Consideremos esto nuestro punto de partida, hagamos una predicción y la ploteamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a meterlo en un dataframe para verlo más claro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"mean_predict\"] = data.nota.mean()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_predict = [data.nota.mean()] * num_notas\n",
    "plt.scatter(X,y)\n",
    "plt.plot(X, mean_predict, lw=3)\n",
    "plt.vlines(X, mean_predict, y, lw=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos TSS para el modelo anterior\n",
    "TSS = ((data.nota - data.mean_predict)** 2).sum()\n",
    "TSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que los coeficientes de la regresión lineal minimizan el $RSS=Sigma(y_i - \\hat{y_i})^2$, es decir, la cantidad de variabilidad que queda sin explicar después de realizar la regresión. El [coeficiente de determinación](https://en.wikipedia.org/wiki/Coefficient_of_determination):\n",
    "\n",
    "$$R^2 = \\frac{TSS -RSS}{TSS} = 1-\\frac{RSS}{TSS}$$\n",
    "\n",
    "mide la \"*proporción de variabilidad en Y que puede explicarse mediante X*\". Es una medida de la relación lineal que existe entre $X$ e $y$.\n",
    "\n",
    "**Nota:** en el caso de la regresión lineal simple, el coeficiente $R^2$ no es más que el cuadrado del coeficiente de correlación de *Pearson* que ya conocemos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculamos el R2 del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"predict_model\"] = data.horas * beta_1 + beta_0\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RSS = ((data.nota - data.predict_model) **2 ).sum()\n",
    "RSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2\n",
    "r2 = (TSS - RSS) / (TSS)\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R^2$ mide lo bueno que es nuestro modelo de regresión. Cuanto más grande, mejor. Es un valor entre 0 y 1    \n",
    "**NOTA**: es computable para cualquier modelo, no importa si es lineal o no. Sólo se necesitan los valores reales y los predichos.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal con sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardo las variables x,y\n",
    "X = data[[\"horas\"]]\n",
    "y = data.nota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entreno el algoritmo\n",
    "lr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"notas_sklearn\"] = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE: \", metrics.mean_absolute_error(data.nota, data.notas_sklearn))\n",
    "print(\"MSE: \", metrics.mean_squared_error(data.nota, data.notas_sklearn))\n",
    "print(\"RMSE: \" , np.sqrt(metrics.mean_squared_error(data.nota, data.notas_sklearn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Cálculo del error medio absoluto, del error medio cuadrático y del error medio cuadrático\n",
    "\n",
    "- **MAE** es el más fácil de entender, porque es el error medio.\n",
    "- **El MSE** es más popular que el MAE, porque el MSE \"castiga\" los errores más grandes, lo que suele ser útil en el mundo real.\n",
    "- **RMSE** es aún más popular que MSE, es la raíz cuadrada del MSE y mide la desviación estándar de los residuos.\n",
    "\n",
    "Todas estas son **funciones de pérdida**, porque queremos minimizarlas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lee más sobre MAE, MSE, RMSE Y R2 [AQUÍ](http://medium.com/analytics-vidhya/mae-mse-rmse-coefficient-of-determination-adjusted-r-squared-which-metric-is-better-cd0326a5697e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal con statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para no variar, un poquito de [documentación](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.html)      \n",
    "Y [este artículo](https://jyotiyadav99111.medium.com/statistics-how-should-i-interpret-results-of-ols-3bde1ebeec01) que resume cómo interpretar la información del summary del OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smf.ols(\"nota ~ horas\", data=data).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptos del OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  <b>R2</b> : El coeficiente de determinación mide cuanta de la variación de 𝑦 es explicada por el modelo.\n",
    "Si la varianza de los errores o residuales 𝜎2𝑒 es cero, el modelo explica el 100% de la variable 𝑦. Si 𝜎2𝑒 es igual a la varianza de 𝑦 el modelo no explica nada y 𝑅2 vale cero.\n",
    "\n",
    "\n",
    "- <b>𝑅¯2 </b> : El coeficiente de correlación ajustado 𝑅¯2 corrige el valor de 𝑅2 por la cantidad de variables 𝑘 (igual a 2 para el caso analizado) y la cantidad de datos  𝑁\n",
    "\n",
    "- <b>P value </b> Un p-valor bajo (< 0.05) indica que la variable es un buen predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal múltiple\n",
    "\n",
    "Por supuesto, las horas que uno estudia no son el único factor importante para sacar buenas notas en el mundo real. Podemos pensar en el cociente intelectual, por ejemplo, como otro factor determinante. De hecho, podemos generalizar un modelo lineal para tener tantas variables como queramos:\n",
    "\n",
    " $$ Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_2 X_m + \\epsilon$$\n",
    " \n",
    " En este caso lo que vamos a hacer, es añadir una variable que nos resta de la nota, las horas de fiesta.\n",
    " Imaginemos que por cada hora que salimos de fiesta mueren neuronas en nuestro cerebro y se nos olvida información, por tanto, nos restará nota (recordad que estamos inventando datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a crear el dataframe con las notas\n",
    "# Del ejemplo visto ayer en clase \n",
    "beta_0 = 10\n",
    "beta_1 = 0.08\n",
    "beta_2 = -0.03\n",
    "num_notas = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horas_estudio = np.random.normal(500,200,num_notas)\n",
    "horas_fiesta = np.random.normal(500,200, num_notas)\n",
    "y = (beta_0) + (beta_1 * horas_estudio) + (beta_2 * horas_fiesta) + (np.random.normal(loc=0, scale=5, size=num_notas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(\n",
    "    {\"notas\": y,\n",
    "    \"horas_estudio\":  horas_estudio,\n",
    "    \"horas_fiesta\": horas_fiesta}\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los coeficientes de la regresión lineal múltiple se calculan de forma similar al caso de la regresión lineal simple: minimizan\n",
    "\n",
    "$$RSS = \\Sigma(y_i - \\hat{y_i})^2$$\n",
    "\n",
    "\n",
    "donde:\n",
    "\n",
    " $$ \\hat{y} = \\hat{beta_0} + \\hat{beta_1 X_1} + \\hat{beta_2} X_2 + \\hat + \\hat{\\beta_2} X_m$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizamos los resultados con el OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = smf.ols(\"notas ~ horas_estudio + horas_fiesta\", data=data).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables categóricas\n",
    "\n",
    "Muy a menudo nos enfrentamos a situaciones en las que los predictores son de naturaleza *cualitativa*. Un buen ejemplo podría ser el sexo de una persona, que puede tomar los valores $M$ o $F$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sex\"] = np.random.choice([\"M\", \"H\"], num_notas)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sex.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ¿Cómo trabajamos estas variables? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"es_mujer\"] = data.sex.str.get_dummies()[\"M\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluimos esta información en el modelo a través de una variable *dummy*:\n",
    "$$\n",
    "x_i= \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      1  \\quad \\text{si la persona es mujer} \\\\\n",
    "      0  \\quad \\text{si la persona es hombre} \\\\\n",
    "\\end{array} \n",
    "\\right. \n",
    "$$\n",
    "\n",
    "\n",
    "Si esta es nuestra única variable, esto resulta en un modelo:\n",
    "\n",
    "$$y_i = \\beta_0 + \\beta_1 x_i +\\epsilon_i = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      \\beta_0 + \\beta_1 +\\epsilon_i  \\quad \\text{si la persona es mujer} \\\\\n",
    "      \\beta_0 + \\epsilon_i  \\quad \\text{si la persona es hombre} \\\\\n",
    "\\end{array} \n",
    "\\right.  $$\n",
    "\n",
    "En este caso, $\\beta_0$ representa la nota media de los hombres, y $\\beta_0 + \\beta_1$ la nota media de las mujeres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smf.ols(\"notas ~ horas_estudio + horas_fiesta + es_mujer\", data = data).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensiones del modelo lineal\n",
    "\n",
    "Hay varios supuestos que se utilizan al ajustar un modelo lineal.        \n",
    "Asunciones del modelo líneal [VÍDEO](https://www.youtube.com/watch?v=hVe2F9krrWk)\n",
    "* Los errores se distribuyen normalmente y tienen una varianza constante\n",
    "* Los errores no están correlacionados entre sí\n",
    "* **Supuesto aditivo** El efecto de los cambios en un predictor $X_j$ sobre la respuesta $Y$ es independiente de los valores de los otros predictores.\n",
    "* **Supuesto lineal** El cambio en la respuesta para un aumento de una unidad en $X_j$ es el mismo sin importar el valor de $X_j$.\n",
    "\n",
    "### Desafiando la suposición aditiva: la sinergia\n",
    "\n",
    "A veces nuestras variables tendrán interacciones naturales. Por ejemplo, podemos pensar que cuanto más se escuchen nuestros anuncios en la radio, más eficaces serán nuestros anuncios en la televisión. Es decir, el efecto de ambos es *mayor* (o *menor*) que la suma de las partes.\n",
    "\n",
    "Este es un tema comúnmente estudiado en [marketing](https://smallbusiness.chron.com/definition-synergy-marketing-21786.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv = pd.read_csv('../datasets/Advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manos a la obra\n",
    "* Crear tres modelos independientes de regresión lineal simple\n",
    "    * Interpretar los resultados\n",
    "* Crear un modelo multivariante con los tres predictores\n",
    "    * Interpretar los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_adv[[\"Radio\"]]\n",
    "y = df_adv.Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv[\"nueva\"] = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regalo para el lab de hoy \n",
    "df_adv.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smf.ols(\"Sales ~ TV\", data = df_adv).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smf.ols(\"Sales ~ TV + Radio + Newspaper\", data = df_adv).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smf.ols(\"Sales ~ TV + Radio\", data = df_adv).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smf.ols(\"Sales ~  TV + Radio + TV * Radio\", data = df_adv).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La diferencia es que la covarianza nos da la dirección (positiva o negativa) entre las variables y la correlación nos da esto más la fuerza de esta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerde el **principio jerárquico:**\n",
    "\n",
    "\"*Si incluimos una interacción en un modelo, debemos incluir también los efectos principales, incluso si los valores p que se asocian a sus coeficientes no son significativos*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  $R^2$ Ajustado \n",
    "Hay una cosa curiosa con $R^2$. ¡¡Mira lo que pasa cuando incluimos variables *al azar*!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv['rand_1'] = np.random.normal(size=200)\n",
    "df_adv['rand_2'] = np.random.normal(size=200)\n",
    "df_adv['rand_3'] = np.random.normal(size=200)\n",
    "df_adv['rand_4'] = np.random.normal(size=200)\n",
    "df_adv['rand_5'] = np.random.normal(size=200)\n",
    "df_adv['rand_6'] = np.random.normal(size=200)\n",
    "df_adv['rand_7'] = np.random.normal(size=200)\n",
    "df_adv['rand_8'] = np.random.normal(size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_adv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smf.ols(\"Sales ~  TV + Radio + TV * Radio + rand_1 + rand_2 + rand_3 + rand_4 + rand_5 + rand_6 + rand_7 + rand_8\", data = df_adv).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El coeficiente `Adj. R-cuadrado` pretende penalizar el $R^2$ de un modelo cuando se incluyen *demasiadas* varaibles. \n",
    "$$\\bar R^2 = 1-(1-R^2){n-1 \\ sobre n-p-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección por pasos\n",
    "Siempre hay que intentar tener un modelo lo más sencillo posible. Habrá otras formas de hacerlo utilizando la **regularización**, veremos más adelante cómo hay librerías que nos ayudarán a decidir si nos quedamos con unas u otras variables, pero hasta ahora los métodos que describimos aquí son bastante útiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best subset selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso de best subset selection consiste en evaluar todos los posibles modelos que se pueden crear por combinación de los predictores disponibles. El algoritmo a seguir para k predictores es:\n",
    "\n",
    "- Se genera lo que se conoce como modelo nulo (M0), que es el modelo sin ningún predictor.\n",
    "\n",
    "- Se generan todos los posibles modelos que contienen un único predictor y se selecciona el que tiene menor error de entrenamiento. Al modelo seleccionado se denomina (M1).\n",
    "\n",
    "- Se repite el paso anterior para modelos con dos predictores y así sucesivamente hasta llegar al modelo con todos los predictores (Mk).\n",
    "\n",
    "- De entre los mejores modelos seleccionados para cada número de predictores (M0, M1, M2,…,Mk) se identifica el mejor modelo, esta vez empleando una métrica de validación (R2 Ajustado).     \n",
    "\n",
    "A pesar de que este método explora todas las posibilidades, tiene dos limitaciones fundamentales:\n",
    "Requerimientos computacionales: Se requiere calcular 2p modelos distintos, lo que lo hace inviable para más de 40 predictores.\n",
    "Problemas de overfitting. Al generarse tantos modelos, por simple azar se pueden encontrar buenos resultados. Por esta razón best subset selection no se ecominda si hay más de 10 predictores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo nulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smf.ols(\"Sales ~ 1\", data=df_adv).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward stepwise selection\n",
    "\n",
    "Forward stepwise selection es una alternativa computacionalmente más eficiente que best subset selection, en la que no se evalúan todas las posibles combinaciones de predictores sino solo un subconjunto. El proceso se inicia generando el modelo nulo (M0) sin predictores. A continuación, se generan todos los posibles modelos que se pueden crear añadiendo un predictor al modelo nulo. De entre todos estos modelos con 1 predictor se selecciona el mejor basándose en el error de entrenamiento, al modelo elegido se denomina M1. Se repite el paso anterior, pero esta vez partiendo del último modelo seleccionado y así sucesivamente hasta llegar al modelo con todos los predictores. De entre los mejores modelos seleccionados para cada número de predictores (M0, M1, M2,…,Mk), se identifica el mejor, esta vez empleando una métrica de validación (validación cruzada, Cp, AIC, BIC o R2ajustado).\n",
    "\n",
    "Al crear modelos anidados, en los que el modelo k se construye a partir del modelo k−1, el método forward stepwise selection no garantiza que se seleccione el mejor modelo de entre todos los posibles, ya que no se evalúan todas las posibles combinaciones. Sin embargo, suele llegar a modelos óptimos consiguiendo un buen rendimiento computacional y evitando el overfitting. Otra ventaja añadida es que, forward stepwise selection puede emplearse incluso cuando el número de predictores es mayor que el de observaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero:  \n",
    "1. Todos los modelos con una sola variable. Uno gana. Ganador A\n",
    "2. Añade a este modelo todas las variables, una por una. Uno gana. Ganador B \n",
    "3. Añade a este modelo todas las variables, una por una. Uno gana. Ganador C\n",
    "...\n",
    "...\n",
    "\n",
    "FIN: tomar el ganador entre A, B, C, D...\n",
    "\n",
    "Si R2 tiene dos decimales iguales, consideramos el modelo con más variables representativas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problemas potenciales en la regresión lineal\n",
    "\n",
    "Los principales supuestos de un modelo lineal son:\n",
    "\n",
    "* Los datos son lineales \n",
    "* Los errores no están correlacionados\n",
    "* La varianza de los términos de error es constante\n",
    "\n",
    "¿Qué ocurre si no se cumplen estos supuestos? \n",
    "\n",
    "Además, nuestros modelos pueden sufrir otros problemas como:\n",
    "* Valores atípicos\n",
    "* Puntos de apalancamiento elevados\n",
    "* Colinealidad\n",
    "* Valores perdidos\n",
    "\n",
    "Ved este [vídeo](https://www.youtube.com/watch?v=hVe2F9krrWk) para una introducción al tema.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos cuatro conjuntos de datos son distintos, pero resulta que tienen la misma media aritmética y varianza de los valores x e y, la misma correlación, el mismo coeficiente de correlación y la misma recta de regresión. algunos con 2 ó 3 decimales. Son el Cuarteto de Anscombe, llamado así por F.J. Anscombe, un matemático estadista que los publicó en 1973. Se suelen utilizara para enseñar que además de calcular las propiedades estadística de los datos, conviene visualizarlos.\n",
    "\n",
    "En todos los casos las representaciones nos dicen algo más sobre los datos: los primeros parecen un tanto aleatorios pero relacionados, los segundos muestran un patrón claro pero notablemente diferente; en el tercero y el cuarto hay otros patrones enturbiados por algunos valores anómalos. Estos valores pueden ser errores, datos reales que simplemente están fuera de lo normal o incluso datos producidos artificialmente para que todo encaje.\n",
    "\n",
    "Moraleja: no te fíes ciegamente de los datos y tampoco de las estadísticas que obtenga de ellos; procura montar además una visualización para entenderlos.\n",
    "![anscombe](../images/anscombe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Echa un ojo a [Wikipedia](https://en.wikipedia.org/wiki/Anscombe%27s_quartet) que dice que:       \n",
    "El cuarteto de Anscombe consta de cuatro conjuntos de datos que tienen estadísticas descriptivas simples casi idénticas, pero que tienen distribuciones muy diferentes y aparecen de forma muy distinta cuando se grafican. Cada conjunto de datos consta de once puntos (x,y). Fueron construidos en 1973 por el estadístico Francis Anscombe para demostrar tanto la importancia de graficar los datos antes de analizarlos como el efecto de los valores atípicos y otras observaciones influyentes en las propiedades estadísticas. Describió el artículo como un intento de contrarrestar la impresión entre los estadísticos de que \"los cálculos numéricos son exactos, pero los gráficos son toscos\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cómo evaluar a partir de distintas métricas si nuestro modelo es bueno o malo (R2,RMSE,MSE,MAE)\n",
    "- P valor importante: nos ayuda a saber si las variables predictoras son significativas o no\n",
    "- Tener en cuenta posibles efectos multiplicadores sobre las variables (desafiamos la suposición aditiva, tenemos dominio de los datos)\n",
    "- R2 Ajustado siempre va a ser menor que el R2 porque resta por cada columna/variable\n",
    "- Variables categóricas - Las encodeamos con GET DUMMIES \n",
    "- Summary del OLS no solo vemos los coeficientes (intercept / coef de cada variable) si no también la importancia de esas variables, el R2 y otras pruebas estadísticas\n",
    "- Al final lo que queremos calcular cuando hacemos una regresión o nos enfrentamos a un problema de regresión lineal ya sea con una variable o multivariable es LA ECUACIÓN DE UNA RECTA por eso tendremos la ordenada en el origen y la pendiente, será una recta de N dimensiones si tengo N variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Materials \n",
    "\n",
    "* One example of [linear regression with the Boston data set](https://towardsdatascience.com/linear-regression-on-boston-housing-dataset-f409b7e4a155)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
