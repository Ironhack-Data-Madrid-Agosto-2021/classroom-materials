{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hearing-freedom",
   "metadata": {},
   "source": [
    "# <center> Procesamiento de lenguaje natural (NLP)</center>\n",
    "El [procesamiento de lenguaje natural](https://es.wikipedia.org/wiki/Procesamiento_de_lenguajes_naturales), abreviado PLN3 ‚Äîen ingl√©s, natural language processing, NLP‚Äî es un campo de las ciencias de la computaci√≥n, de la inteligencia artificial y de la ling√º√≠stica que estudia las interacciones entre las computadoras y el lenguaje humano. Se ocupa de la formulaci√≥n e investigaci√≥n de mecanismos eficaces computacionalmente para la comunicaci√≥n entre personas y m√°quinas por medio del lenguaje natural, es decir, de las lenguas del mundo. No trata de la comunicaci√≥n por medio de lenguas naturales de una forma abstracta, sino de dise√±ar mecanismos para comunicarse que sean eficaces computacionalmente ‚Äîque se puedan realizar por medio de programas que ejecuten o simulen la comunicaci√≥n‚Äî.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-questionnaire",
   "metadata": {},
   "source": [
    "![elgif](https://media.giphy.com/media/xT0xeJpnrWC4XWblEk/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-criminal",
   "metadata": {},
   "source": [
    "NLP es considerado uno de los grandes retos de la inteligencia artificial ya que es una de las tareas m√°s complicadas y desafiantes: ¬øc√≥mo comprender realmente el significado de un texto? ¬øc√≥mo intuir neolog√≠smos, ir√≥nias, chistes √≥ poes√≠a? Si la estrategia/algoritmo que utilizamos no sortea esas dificultades de nada nos servir√°n los resultados obtenidos.\n",
    "En NLP no es suficiente con comprender meras palabras, se deber√° comprender al conjunto de palabras que conforman una oraci√≥n, y al conjunto de lineas que comprenden un p√°rrafo. Dando un sentido global al an√°lisis del texto/discurso para poder sacar buenas conclusiones.\n",
    "\n",
    "Nuestro lenguaje est√° lleno de ambig√ºedades, de palabras con distintas acepciones, giros y diversos significados seg√∫n el contexto. Esto hace que el NLP sea una de las tareas m√°s dif√≠ciles de dominar.     \n",
    "\n",
    "![madfalda](https://www.aprendemachinelearning.com/wp-content/uploads/2018/12/mafalda_mundo.png)\n",
    "\n",
    "Por tanto, la dificultad del NLP est√° en varios niveles:\n",
    "\n",
    "Ambig√ºedad:\n",
    "\n",
    "- Nivel l√©xico: por ejemplo, varios significados\n",
    "- Nivel referencial: an√°foras, met√°foras, etc...\n",
    "- Nivel estructural: la sem√°ntica es necesaria para entender la estructura de una oraci√≥n\n",
    "- Nivel pragm√°tico: dobles sentidos, iron√≠a, humor\n",
    "- Detecci√≥n de espacios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-mission",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Los-datos\" data-toc-modified-id=\"Los-datos-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Los datos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Conexiones-con-Mongo\" data-toc-modified-id=\"Conexiones-con-Mongo-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Conexiones con Mongo</a></span></li></ul></li><li><span><a href=\"#Nos-traemos-todos-los-datos-a-un-dataframe-desde-Mongo\" data-toc-modified-id=\"Nos-traemos-todos-los-datos-a-un-dataframe-desde-Mongo-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Nos traemos todos los datos a un dataframe desde Mongo</a></span></li><li><span><a href=\"#Nos-traemos-todos-los-datos-a-un-dataframe-desde-MySQL\" data-toc-modified-id=\"Nos-traemos-todos-los-datos-a-un-dataframe-desde-MySQL-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Nos traemos todos los datos a un dataframe desde MySQL</a></span></li><li><span><a href=\"#Limpiamos-un-poco-üßπ\" data-toc-modified-id=\"Limpiamos-un-poco-üßπ-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Limpiamos un poco üßπ</a></span><ul class=\"toc-item\"><li><span><a href=\"#Vamos-a-limpiarlo-con-Regex\" data-toc-modified-id=\"Vamos-a-limpiarlo-con-Regex-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Vamos a limpiarlo con Regex</a></span></li><li><span><a href=\"#Vamos-a-crear-una-nueva-columna-limpia\" data-toc-modified-id=\"Vamos-a-crear-una-nueva-columna-limpia-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Vamos a crear una nueva columna limpia</a></span></li></ul></li><li><span><a href=\"#NLP\" data-toc-modified-id=\"NLP-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>NLP</a></span><ul class=\"toc-item\"><li><span><a href=\"#Stop-Words\" data-toc-modified-id=\"Stop-Words-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Stop Words</a></span></li><li><span><a href=\"#Tokenizar\" data-toc-modified-id=\"Tokenizar-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Tokenizar</a></span></li></ul></li><li><span><a href=\"#WordClouds\" data-toc-modified-id=\"WordClouds-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>WordClouds</a></span><ul class=\"toc-item\"><li><span><a href=\"#Generamos-un-WorCloud-de-una-canci√≥n\" data-toc-modified-id=\"Generamos-un-WorCloud-de-una-canci√≥n-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Generamos un WorCloud de una canci√≥n</a></span></li><li><span><a href=\"#Tambi√©n-podemos-generarlo-de-un-dataframe-entero\" data-toc-modified-id=\"Tambi√©n-podemos-generarlo-de-un-dataframe-entero-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Tambi√©n podemos generarlo de un dataframe entero</a></span></li></ul></li><li><span><a href=\"#Traducimos\" data-toc-modified-id=\"Traducimos-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Traducimos</a></span></li><li><span><a href=\"#Sentiment-analysis\" data-toc-modified-id=\"Sentiment-analysis-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Sentiment analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#TextBlob\" data-toc-modified-id=\"TextBlob-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>TextBlob</a></span></li><li><span><a href=\"#NLTK\" data-toc-modified-id=\"NLTK-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>NLTK</a></span></li><li><span><a href=\"#¬øOs-acord√°is-de-que-hab√≠amos-hecho-una-funci√≥n-que-tokenizaba?\" data-toc-modified-id=\"¬øOs-acord√°is-de-que-hab√≠amos-hecho-una-funci√≥n-que-tokenizaba?-8.3\"><span class=\"toc-item-num\">8.3&nbsp;&nbsp;</span>¬øOs acord√°is de que hab√≠amos hecho una funci√≥n que tokenizaba?</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-mixer",
   "metadata": {},
   "source": [
    "##¬†Los datos\n",
    "Nos los vamos a traer de una de nuestras bases de datos, en este caso MongoDB\n",
    "###¬†Conexiones con Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-paintball",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con el comando MongoClient establecemos conexi√≥n con el servidor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-emphasis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "#¬†¬øNos acordamos de c√≥mo podemos ver una lista de las caanciones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-pontiac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-train",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "refined-hopkins",
   "metadata": {},
   "source": [
    "## Nos traemos todos los datos a un dataframe desde Mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-burning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-religious",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-cisco",
   "metadata": {},
   "source": [
    "## Nos traemos todos los datos a un dataframe desde MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-starter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-arbor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-storm",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-practice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-recording",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "technical-rainbow",
   "metadata": {},
   "source": [
    "## Limpiamos un poco üßπ\n",
    "Una primera limpieza inicial que vamos a hacer es quitar las partres en las que nos indica estrofa/estribillo de las letras de las canciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-aggregate",
   "metadata": {},
   "source": [
    "### Vamos a limpiarlo con Regex\n",
    "Vemos que se cumple un patr√≥n, y es que son frases o palabras entre corchetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-ordering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un patr√≥n para quitar las frase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-butter",
   "metadata": {},
   "source": [
    "Automatizamos en funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-incident",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "friendly-developer",
   "metadata": {},
   "source": [
    "### Vamos a crear una nueva columna limpia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-sperm",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-shooting",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-hacker",
   "metadata": {},
   "source": [
    "###¬†Stop Words\n",
    "\n",
    "Palabras vac√≠as es el nombre que reciben las palabras sin significado como art√≠culos, pronombres, preposiciones, etc. que son filtradas antes o despu√©s del procesamiento de datos en lenguaje natural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-symphony",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-dryer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-divide",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-camping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy\n",
    "import string\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-holder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-velvet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-ownership",
   "metadata": {},
   "source": [
    "### Tokenizar\n",
    "Una de las formas de normalizar nuestros tokens es mediante stemming y lemmatization.\n",
    "El stemming consiste en quitar y reemplazar sufijos de la ra√≠z de la palabra. La lemmatizaci√≥n es un poco m√°s compleja e implica hacer un an√°lisis del vocabulario y su morfolog√≠a para retornar la forma b√°sica de la palabra (sin conjugar, en singular, etc).    \n",
    "Leed [este](https://medium.com/escueladeinteligenciaartificial/procesamiento-de-lenguaje-natural-stemming-y-lemmas-f5efd90dca8) interesante art√≠culo.\n",
    "A la hora de tokenizar, vamos a hacerlo quitando previamente las stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-consolidation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-airplane",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-blues",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-terror",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-legislature",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-composer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-federation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenizer(sentence):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-giving",
   "metadata": {},
   "source": [
    "Vamos a escribir una funci√≥n que va a tokenizar las letras de nuestras canciones sin importar si est√°n en castellano o en ingl√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(txt):  # texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-contributor",
   "metadata": {},
   "source": [
    "Comprobamos que funciona pas√°ndole una letra a la funci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-cotton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-momentum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-impression",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-clone",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-consent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "agreed-difficulty",
   "metadata": {},
   "source": [
    "## WordClouds\n",
    "Una nube de palabras o nube de etiquetas es una representaci√≥n visual de las palabras que conforman un texto, en donde el tama√±o es mayor para las palabras que aparecen con m√°s frecuencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-trance",
   "metadata": {},
   "source": [
    "![wordcloud](https://i.imgur.com/8I8aJ1N.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-margin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-flour",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "frank-palace",
   "metadata": {},
   "source": [
    "### Generamos un WorCloud de una canci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-washer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "##¬†Lo hacemos funci√≥n y lo parametrizamos para que podamos reutilizarla con facilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-middle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-midnight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "opened-tobago",
   "metadata": {},
   "source": [
    "###¬†Tambi√©n podemos generarlo de un dataframe entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-threshold",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-organic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "breeding-increase",
   "metadata": {},
   "source": [
    "##¬†Traducimos\n",
    "Un poco a nuestro pesar, aunque hay librer√≠as que funcionan en Castellano (la parte de Spacy entrenada en castellano funciona muy bien), lo cierto es que funcionan mejor en ingl√©s, en general, hay otras librer√≠as que no son tan exactas y a√∫n as√≠ incluso Spacy funciona mejor en ingl√©s, as√≠ que vamos a traducir las letras.     \n",
    "La librer√≠a TextBlob, que vamos a usar m√°s adelante para hacer an√°lisis de sentimientos tambi√©n traduce, pero mejor vamos a utilizar googletrans y su librer√≠a, ojo al instalarla:      \n",
    "`pip install googletrans==3.1.0a0`      \n",
    "Hay que instalar la versi√≥n alfa que la oficial tiene issues.\n",
    "Creamos una columna en el dataframe con todas las letras traducidas, y dejamos la original tambi√©n, por si la necesit√°ramos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos c√≥mo traducir una frase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-mainstream",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-reset",
   "metadata": {},
   "source": [
    "De nuevo seguimos con la t√≥nica de automatizar y hacer funciones para todo y as√≠ poder reutilizar c√≥digo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-department",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-debut",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-order",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "significant-wireless",
   "metadata": {},
   "source": [
    "## Sentiment analysis\n",
    "### TextBlob\n",
    "`TextBlob(the_string).sentiment`      \n",
    "\n",
    "**Argumentos:** `string`<br>\n",
    "**Devuelve:** `polaridad`& `subjetividad`\n",
    "\n",
    "\n",
    "La propiedad de sentimiento devuelve una tupla con nombre de la forma Sentimiento(polaridad, subjetividad). La puntuaci√≥n de la polaridad es un float dentro del rango [-1,0, 1,0]. La subjetividad es un float dentro del rango [0.0, 1.0] donde 0.0 es muy objetivo y 1.0 es muy subjetivo.\n",
    "\n",
    "TextBlob se apoya en dos librer√≠as, NLTK y pattern, os dejo laa [documentaci√≥n](https://textblob.readthedocs.io/en/dev/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-strain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-pipeline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-barrier",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-alabama",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "promotional-musician",
   "metadata": {},
   "source": [
    "### NLTK\n",
    "El kit de herramientas de lenguaje natural, o m√°s com√∫nmente NLTK, es un conjunto de bibliotecas y programas para el procesamiento del lenguaje natural simb√≥lico y estad√≠sticos para el lenguaje de programaci√≥n Python. NLTK incluye demostraciones gr√°ficas y datos de muestra.\n",
    "\n",
    "En este caso vamos a sacar tambi√©n la polaridad con el m√≥dulo [SentimentIntensityAnalizer](https://www.nltk.org/api/nltk.sentiment.html#module-nltk.sentiment.vader)      \n",
    "\n",
    "`sia.polarity_scores(the_string)`\n",
    "\n",
    "**Arumentoss:** `string`<br>\n",
    "**Devuelve:** `polaridad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-corrections",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-excess",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-northern",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "falling-smooth",
   "metadata": {},
   "source": [
    "Informaci√≥n sobre el [compound](https://github.com/cjhutto/vaderSentiment#about-the-scoring)     \n",
    "Es la suma de las puntuaciones normalizada entre -1 y 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-conference",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-trick",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "derived-century",
   "metadata": {},
   "source": [
    "###¬†¬øOs acord√°is de que hab√≠amos hecho una funci√≥n que tokenizaba?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-affect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-practice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-pencil",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-albert",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-catch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-artist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-butterfly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-pressure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
